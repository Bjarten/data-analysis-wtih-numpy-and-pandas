{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling\n",
    "[Data wrangeling](https://en.wikipedia.org/wiki/Data_wrangling) is the process of transforming and mapping data from a \"raw\" format into a format more valuable for further downstream pruposes such as analytics. Read more about data. \n",
    "\n",
    "Data wrangling can be divided into teo steps\n",
    "\n",
    "1. Data acquisition\n",
    "2. Data cleaning\n",
    "\n",
    "\n",
    "## Data acquisition\n",
    "\n",
    "Some ways too aquire data can be\n",
    "    \n",
    "* Downloading files\n",
    "* Accessing an API\n",
    "* Scraping a web page\n",
    "* Combine data from different formats\n",
    "\n",
    "### Comma Separated Values (CSV)\n",
    " A [comma separated value (CSV)](https://en.wikipedia.org/wiki/Comma-separated_values) file is a delimited text file that uses comma to seppate values. The CSV is easy to process with code (unlike [.xlsx](https://fileinfo.com/extension/xlsx)). In Python the contents of a CSV file are commonly represented as a list of . There are two common choices for how to represent each row. In the first option, each row is a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Each row is a list\n",
    "csv = [['Q', 'W', 'E'],\n",
    "       ['R', 'T', 'Y']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second option each row is a dictionary. This option works well if you have a CSV header because then the keys of each dictionary can be column names and the fields can be values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Each row is a dictionary\n",
    "csv = [{'name1': 'Q', 'name2': 'W', 'name3': 'E'},\n",
    "       {'name1': 'R', 'name2': 'T', 'name3': 'Y'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data from CSVs\n",
    "### Python's csv Module\n",
    "We will be using the `unicodecsv` since it comes with Anaconda and has support for unicode. The `unicodecsv` works exactly the same as Python's [`csv`](https://docs.python.org/2/library/csv.html) module, and its documentation page is still the best way to learn how to use the `unicodecsv` library.\n",
    "### Data file\n",
    "Lets have a look at our data file before reading it with `unicodecsv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "account_key,status,join_date,cancel_date,days_to_cancel,is_udacity,is_canceled\n",
      "448,canceled,2014-11-10,2015-01-14,65,True,True\n",
      "448,canceled,2014-11-05,2014-11-10,5,True,True\n",
      "448,canceled,2015-01-27,2015-01-27,0,True,True\n",
      "448,canceled,2014-11-10,2014-11-10,0,True,True\n",
      "448,current,2015-03-10,,,True,False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_extract = ''\n",
    "with open('data_files/enrollments.csv', 'r') as f:\n",
    "    for index, line in enumerate(f):\n",
    "        file_extract += line\n",
    "        if index == 5:\n",
    "            break\n",
    "print(file_extract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data\n",
    "\n",
    "Next we will load the data from some file using `unicodecsv`. The mode `rb` in `open('...', 'rb')` means that the file will be opened for reading. The [`csv`](https://docs.python.org/2/library/csv.html) docummentation page mentions that we need to use this. `rb` stands for Read Binary mode. We are using the `DictReader` since our data have a header row. Our reader will be an iterator, the difference between lists and iteratiors in Python can be found [here](https://www.codementor.io/sheena/python-generators-and-iterators-du1082iua). The iterator let's you write a loop to access each element, but only once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('account_key', '448'),\n",
      "             ('status', 'canceled'),\n",
      "             ('join_date', '2014-11-10'),\n",
      "             ('cancel_date', '2015-01-14'),\n",
      "             ('days_to_cancel', '65'),\n",
      "             ('is_udacity', 'True'),\n",
      "             ('is_canceled', 'True')])\n"
     ]
    }
   ],
   "source": [
    "import unicodecsv\n",
    "from pprint import pprint\n",
    "\n",
    "enrollments = []\n",
    "\n",
    "with open('data_files/enrollments.csv', 'rb') as f:\n",
    "    reader = unicodecsv.DictReader(f)\n",
    "    enrollments = list(reader)\n",
    "\n",
    "pprint(enrollments[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read in two more example files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('acct', '0'),\n",
      "             ('utc_date', '2015-01-09'),\n",
      "             ('num_courses_visited', '1.0'),\n",
      "             ('total_minutes_visited', '11.6793745'),\n",
      "             ('lessons_completed', '0.0'),\n",
      "             ('projects_completed', '0.0')])\n",
      "OrderedDict([('creation_date', '2015-01-14'),\n",
      "             ('completion_date', '2015-01-16'),\n",
      "             ('assigned_rating', 'UNGRADED'),\n",
      "             ('account_key', '256'),\n",
      "             ('lesson_key', '3176718735'),\n",
      "             ('processing_state', 'EVALUATED')])\n"
     ]
    }
   ],
   "source": [
    "daily_engagement = []\n",
    "project_submsissions = []\n",
    "\n",
    "def read_csv(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        reader = unicodecsv.DictReader(f)\n",
    "        return list(reader)\n",
    "\n",
    "daily_engagement = read_csv('data_files/daily_engagement.csv')\n",
    "project_submissions = read_csv('data_files/project_submissions.csv')\n",
    "\n",
    "pprint(daily_engagement[0])\n",
    "pprint(project_submissions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing Data Types\n",
    "All the data that we have read in is represented as strings, it's up to us to convert them to the correct data types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('account_key', '448'),\n",
      "             ('status', 'canceled'),\n",
      "             ('join_date', datetime.datetime(2014, 11, 10, 0, 0)),\n",
      "             ('cancel_date', datetime.datetime(2015, 1, 14, 0, 0)),\n",
      "             ('days_to_cancel', 65),\n",
      "             ('is_udacity', True),\n",
      "             ('is_canceled', True)])\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime as dt\n",
    "\n",
    "# Takes a date as a string, and returns a Python datetime object. \n",
    "# If there is no date given, returns None\n",
    "def parse_date(date):\n",
    "    if date == '':\n",
    "        return None\n",
    "    else:\n",
    "        return dt.strptime(date, '%Y-%m-%d')\n",
    "    \n",
    "# Takes a string which is either an empty string or represents an integer,\n",
    "# and returns an int or None.\n",
    "def parse_maybe_int(i):\n",
    "    if i == '':\n",
    "        return None\n",
    "    else:\n",
    "        return int(i)\n",
    "# Clean up the data types in the enrollments table\n",
    "for enrollment in enrollments:\n",
    "    enrollment['cancel_date'] = parse_date(enrollment['cancel_date'])\n",
    "    enrollment['days_to_cancel'] = parse_maybe_int(enrollment['days_to_cancel'])\n",
    "    enrollment['is_canceled'] = enrollment['is_canceled'] == 'True'\n",
    "    enrollment['is_udacity'] = enrollment['is_udacity'] == 'True'\n",
    "    enrollment['join_date'] = parse_date(enrollment['join_date'])\n",
    "    \n",
    "pprint(enrollments[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('acct', '0'),\n",
      "             ('utc_date', datetime.datetime(2015, 1, 9, 0, 0)),\n",
      "             ('num_courses_visited', 1),\n",
      "             ('total_minutes_visited', 11.6793745),\n",
      "             ('lessons_completed', 0),\n",
      "             ('projects_completed', 0)])\n"
     ]
    }
   ],
   "source": [
    "# Clean up the data types in the engagement table\n",
    "for engagement_record in daily_engagement:\n",
    "    engagement_record['lessons_completed'] = int(float(engagement_record['lessons_completed']))\n",
    "    engagement_record['num_courses_visited'] = int(float(engagement_record['num_courses_visited']))\n",
    "    engagement_record['projects_completed'] = int(float(engagement_record['projects_completed']))\n",
    "    engagement_record['total_minutes_visited'] = float(engagement_record['total_minutes_visited'])\n",
    "    engagement_record['utc_date'] = parse_date(engagement_record['utc_date'])\n",
    "    \n",
    "pprint(daily_engagement[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('creation_date', datetime.datetime(2015, 1, 14, 0, 0)),\n",
      "             ('completion_date', datetime.datetime(2015, 1, 16, 0, 0)),\n",
      "             ('assigned_rating', 'UNGRADED'),\n",
      "             ('account_key', '256'),\n",
      "             ('lesson_key', '3176718735'),\n",
      "             ('processing_state', 'EVALUATED')])\n"
     ]
    }
   ],
   "source": [
    "# Clean up the data types in the submissions table\n",
    "for submission in project_submissions:\n",
    "    submission['completion_date'] = parse_date(submission['completion_date'])\n",
    "    submission['creation_date'] = parse_date(submission['creation_date'])\n",
    "pprint(project_submissions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating the Data\n",
    "Let's find the number of rows and number of unique students in each of the csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enrollments; number of rows: 1640, number of unique students: 1302\n",
      "daily_engagement; number of rows: 136240, number of unique students: 1237\n",
      "project_submsissions; number of rows: 3642, number of unique students: 743\n"
     ]
    }
   ],
   "source": [
    "enrollments_num_of_rows = len(enrollments)\n",
    "engagements_num_of_rows_daily = len(daily_engagement)\n",
    "submissions_num_of_rows_project = len(project_submissions)\n",
    "\n",
    "enrollments_num_of_unique_students = len(set([enrollment['account_key'] for enrollment in enrollments]))\n",
    "daily_engagement_num_of_unique_students = len(set([de['acct'] for de in daily_engagement]))\n",
    "project_submissions_num_of_unique_students = len(set([ps['account_key'] for ps in project_submissions]))\n",
    "\n",
    "print(f'enrollments; number of rows: {enrollments_num_of_rows}, number of unique students: {enrollments_num_of_unique_students}')\n",
    "print(f'daily_engagement; number of rows: {engagements_num_of_rows_daily}, number of unique students: {daily_engagement_num_of_unique_students}')\n",
    "print(f'project_submsissions; number of rows: {submissions_num_of_rows_project}, number of unique students: {project_submissions_num_of_unique_students}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems in the Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple of problems in the data. Fistly, there are more students in enrollment than engagement table, there should have been the same amount in both  tables. Secondly, a column is named 'account_key' in two of the tables and 'acct' in the third, this really isen't a big problem, but it is inconvenient. We will start with changing 'acct' to 'account_key'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "## Rename the \"acct\" column in the daily_engagement table to \"account_key\".\n",
    "\n",
    "for engagement in daily_engagement:\n",
    "    engagement['account_key'] = engagement['acct']\n",
    "    del engagement['acct']\n",
    "daily_engagement\n",
    "print(daily_engagement[0]['account_key'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now make a function for all the data sets to get out unique students,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_students(data):\n",
    "    unique_students = set()\n",
    "    for data_point in data:\n",
    "        unique_students.add(data_point['account_key'])\n",
    "    return unique_students\n",
    "\n",
    "unique_enrolled_students = get_unique_students(enrollments)\n",
    "unique_engagement_students = get_unique_students(daily_engagement)\n",
    "unique_project_submitters = get_unique_students(project_submissions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now on to the second problem, why are students missing from `daily_engagement`? Here is a process to investigate the problem:\n",
    "1. Identify suprising datapoints\n",
    "    - Any enrollment record with no corresponding engagement data\n",
    "2. Print out one or a few surprising data points\n",
    "3. Fix any problems you find\n",
    "    - More investigation may be necessary\n",
    "    - Or there might not be a problem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('account_key', '1304'),\n",
      "             ('status', 'canceled'),\n",
      "             ('join_date', datetime.datetime(2015, 1, 10, 0, 0)),\n",
      "             ('cancel_date', datetime.datetime(2015, 3, 10, 0, 0)),\n",
      "             ('days_to_cancel', 59),\n",
      "             ('is_udacity', True),\n",
      "             ('is_canceled', True)])\n",
      "OrderedDict([('account_key', '1304'),\n",
      "             ('status', 'canceled'),\n",
      "             ('join_date', datetime.datetime(2015, 3, 10, 0, 0)),\n",
      "             ('cancel_date', datetime.datetime(2015, 6, 17, 0, 0)),\n",
      "             ('days_to_cancel', 99),\n",
      "             ('is_udacity', True),\n",
      "             ('is_canceled', True)])\n",
      "OrderedDict([('account_key', '1101'),\n",
      "             ('status', 'current'),\n",
      "             ('join_date', datetime.datetime(2015, 2, 25, 0, 0)),\n",
      "             ('cancel_date', None),\n",
      "             ('days_to_cancel', None),\n",
      "             ('is_udacity', True),\n",
      "             ('is_canceled', False)])\n"
     ]
    }
   ],
   "source": [
    "missing_students = list(unique_enrolled_students - unique_engagement_students)\n",
    "for student in enrollments:\n",
    "    if student['account_key'] in missing_students and student['days_to_cancel'] != 0:\n",
    "        pprint(student)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We discover that the majority of the missing students are students who cancled their subscription the same day they enlisted. Three of the missing students who divirge from this pattern are Udacity test accounts, and we don't want them in our analysis data set. We will remove all Udacity test accounts from our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# Create a set of the account keys for all Udacity test accounts\n",
    "udacity_test_accounts = set()\n",
    "for enrollment in enrollments:\n",
    "    if enrollment['is_udacity']:\n",
    "        udacity_test_accounts.add(enrollment['account_key'])\n",
    "print(len(udacity_test_accounts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given some data with an account_key field, removes any records corresponding to Udacity test accounts\n",
    "def remove_udacity_accounts(data):\n",
    "    non_udacity_data = []\n",
    "    for data_point in data:\n",
    "        if data_point['account_key'] not in udacity_test_accounts:\n",
    "            non_udacity_data.append(data_point)\n",
    "    return non_udacity_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1622\n",
      "135656\n",
      "3634\n"
     ]
    }
   ],
   "source": [
    "# Remove Udacity test accounts from all three tables\n",
    "non_udacity_enrollments = remove_udacity_accounts(enrollments)\n",
    "non_udacity_engagement = remove_udacity_accounts(daily_engagement)\n",
    "non_udacity_submissions = remove_udacity_accounts(project_submissions)\n",
    "\n",
    "print(len(non_udacity_enrollments))\n",
    "print(len(non_udacity_engagement))\n",
    "print(len(non_udacity_submissions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:np]",
   "language": "python",
   "name": "conda-env-np-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
