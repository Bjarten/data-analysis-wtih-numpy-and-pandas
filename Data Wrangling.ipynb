{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling\n",
    "[Data wrangeling](https://en.wikipedia.org/wiki/Data_wrangling) is the process of transforming and mapping data from a \"raw\" format into a format more valuable for further downstream pruposes such as analytics. Read more about data. \n",
    "\n",
    "Data wrangling can be divided into teo steps\n",
    "\n",
    "1. Data acquisition\n",
    "2. Data cleaning\n",
    "\n",
    "\n",
    "## Data acquisition\n",
    "\n",
    "Some ways too aquire data can be\n",
    "    \n",
    "* Downloading files\n",
    "* Accessing an API\n",
    "* Scraping a web page\n",
    "* Combine data from different formats\n",
    "\n",
    "### Comma Separated Values (CSV)\n",
    " A [comma separated value (CSV)](https://en.wikipedia.org/wiki/Comma-separated_values) file is a delimited text file that uses comma to seppate values. The CSV is easy to process with code (unlike [.xlsx](https://fileinfo.com/extension/xlsx)). In Python the contents of a CSV file are commonly represented as a list of . There are two common choices for how to represent each row. In the first option, each row is a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Each row is a list\n",
    "csv = [['Q', 'W', 'E'],\n",
    "       ['R', 'T', 'Y']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second option each row is a dictionary. This option works well if you have a CSV header because then the keys of each dictionary can be column names and the fields can be values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-29-b2feb635b49a>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-29-b2feb635b49a>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    {'name1': 'R', 'name2': 'T', 'name3': 'Y'}]\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# Option 2: Each row is a dictionary\n",
    "csv = {'name1': 'Q', 'name2': 'W', 'name3': 'E'},\n",
    "       {'name1': 'R', 'name2': 'T', 'name3': 'Y'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data from CSVs\n",
    "### Python's csv Module\n",
    "We will be using the `unicodecsv` since it comes with Anaconda and has support for unicode. The `unicodecsv` works exactly the same as Python's [`csv`](https://docs.python.org/2/library/csv.html) module, and its documentation page is still the best way to learn how to use the `unicodecsv` library.\n",
    "### Data file\n",
    "Lets have a look at our data file before reading it with `unicodecsv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "account_key,status,join_date,cancel_date,days_to_cancel,is_udacity,is_canceled\n",
      "448,canceled,2014-11-10,2015-01-14,65,True,True\n",
      "448,canceled,2014-11-05,2014-11-10,5,True,True\n",
      "448,canceled,2015-01-27,2015-01-27,0,True,True\n",
      "448,canceled,2014-11-10,2014-11-10,0,True,True\n",
      "448,current,2015-03-10,,,True,False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_extract = ''\n",
    "with open('data_files/enrollments.csv', 'r') as f:\n",
    "    for index, line in enumerate(f):\n",
    "        file_extract += line\n",
    "        if index == 5:\n",
    "            break\n",
    "print(file_extract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data\n",
    "\n",
    "Next we will load the data from some file using `unicodecsv`. The mode `rb` in `open('...', 'rb')` means that the file will be opened for reading. The [`csv`](https://docs.python.org/2/library/csv.html) docummentation page mentions that we need to use this. `rb` stands for Read Binary mode. We are using the `DictReader` since our data have a header row. Our reader will be an iterator, the difference between lists and iteratiors in Python can be found [here](https://www.codementor.io/sheena/python-generators-and-iterators-du1082iua). The iterator let's you write a loop to access each element, but only once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('account_key', '448'),\n",
       "             ('status', 'canceled'),\n",
       "             ('join_date', '2014-11-10'),\n",
       "             ('cancel_date', '2015-01-14'),\n",
       "             ('days_to_cancel', '65'),\n",
       "             ('is_udacity', 'True'),\n",
       "             ('is_canceled', 'True')])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unicodecsv\n",
    "\n",
    "enrollments = []\n",
    "\n",
    "with open('data_files/enrollments.csv', 'rb') as f:\n",
    "    reader = unicodecsv.DictReader(f)\n",
    "    enrollments = list(reader)\n",
    "\n",
    "enrollments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:np]",
   "language": "python",
   "name": "conda-env-np-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
